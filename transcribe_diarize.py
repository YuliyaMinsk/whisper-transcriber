# –ù—É–∂–µ–Ω Python 3.11.9, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ª–æ–∫–∞–ª—å–Ω–æ, –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏ (—Å–º. requirements.txt).
# –ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞ —Å–æ–∑–¥–∞–π –∏ –∞–∫—Ç–∏–≤–∏—Ä—É–π –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ, –∑–∞—Ç–µ–º –∑–∞–ø—É—Å—Ç–∏ —Å–∫—Ä–∏–ø—Ç:
#
# python -m venv .venv
# source .venv/bin/activate
# pip install -r requirements.txt
# python transcribe_diarize.py [--speakers N]
#
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
#   python transcribe_diarize.py              # –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ø–∏–∫–µ—Ä–æ–≤
#   python transcribe_diarize.py -s 2         # —è–≤–Ω–æ —É–∫–∞–∑–∞—Ç—å 2 —Å–ø–∏–∫–µ—Ä–∞
#   python transcribe_diarize.py --speakers 3 # —è–≤–Ω–æ —É–∫–∞–∑–∞—Ç—å 3 —Å–ø–∏–∫–µ—Ä–∞
#   python transcribe_diarize.py --help       # –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø—Ä–∞–≤–∫—É
#
# –í—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã –±–µ—Ä—ë–º –∏–∑ –ø–∞–ø–∫–∏ "audio".
# –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ WAV-—Ñ–∞–π–ª—ã –∫–ª–∞–¥—ë–º –≤ "temp_audio".
# –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–¥–∏–∞–ª–æ–≥–∏ —Å–æ —Å–ø–∏–∫–µ—Ä–∞–º–∏) —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –æ–¥–Ω—É –ø–∞–ø–∫—É "transcripts":
#   - <basename>.diarized.txt
#   - <basename>.diarized.json
#
# –ü—Ä–∏–º–µ—á–∞–Ω–∏—è:
# - –î–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è/–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π ffmpeg –≤ —Å–∏—Å—Ç–µ–º–µ (brew/apt/choco).
# - –ú–∞–ø–ø–∏–Ω–≥ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ Whisper - —Å–ø–∏–∫–µ—Ä—ã –¥–µ–ª–∞–µ–º –ø–æ "—Å–µ—Ä–µ–¥–∏–Ω–µ" —Å–µ–≥–º–µ–Ω—Ç–∞.
#   –ü—Ä–∏ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–∏ –Ω–∞–∑–Ω–∞—á–∞–µ–º —Å–ø–∏–∫–µ—Ä–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –ø–æ–∫—Ä—ã—Ç–∏–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏.

import os
import json
import math
import subprocess
import argparse
from typing import List, Tuple, Dict, Optional, Union

import whisper  # openai-whisper, –º–æ–∂–Ω–æ –µ—â–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å faster-whisper
from simple_diarizer.diarizer import Diarizer

try:
    import torchaudio
    if hasattr(torchaudio, "set_audio_backend"):
        torchaudio.set_audio_backend("soundfile");
except Exception:
    pass


AUDIO_FOLDER: str = "audio"
TEMP_AUDIO_FOLDER: str = "temp_audio"
OUTPUT_FOLDER: str = "transcripts"

SUPPORTED_EXTENSIONS: Tuple[str, ...] = (".ogg", ".opus", ".mp3", ".wav", ".m4a", ".mp4")

WHISPER_MODEL_NAME: str = "medium"
WHISPER_LANGUAGE: str = "ru"

SPEAKER_PREFIX: str = "SPEAKER_"

TARGET_SAMPLE_RATE: int = 16000
TARGET_CHANNELS: int = 1


def ensure_directories() -> None:
    """–°–æ–∑–¥–∞—ë—Ç —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–∞–ø–∫–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏."""
    os.makedirs(TEMP_AUDIO_FOLDER, exist_ok=True)
    os.makedirs(OUTPUT_FOLDER, exist_ok=True)


def is_supported(filename: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –ø–æ–¥ —Å–ø–∏—Å–æ–∫ SUPPORTED_EXTENSIONS."""
    return filename.lower().endswith(SUPPORTED_EXTENSIONS)


def run_ffmpeg_to_wav_16k_mono(input_path: str, output_wav_path: str) -> None:
    """
    –ü—Ä–∏–≤–æ–¥–∏—Ç –ª—é–±–æ–π –≤—Ö–æ–¥ (–∞—É–¥–∏–æ/–≤–∏–¥–µ–æ) –∫ WAV 16–∫–ì—Ü –º–æ–Ω–æ.
    –¢—Ä–µ–±—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π ffmpeg –≤ —Å–∏—Å—Ç–µ–º–µ.
    """
    # -y: –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å; -ac 1: –º–æ–Ω–æ; -ar 16000: —á–∞—Å—Ç–æ—Ç–∞; -vn: –±–µ–∑ –≤–∏–¥–µ–æ
    command: List[str] = [
        "ffmpeg", "-y", "-i", input_path,
        "-vn", "-ac", str(TARGET_CHANNELS),
        "-ar", str(TARGET_SAMPLE_RATE),
        "-f", "wav",
        output_wav_path,
    ]
    try:
        subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
    except FileNotFoundError:
        raise RuntimeError("ffmpeg –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏ ffmpeg (–Ω–∞–ø—Ä–∏–º–µ—Ä, brew install ffmpeg).")
    except subprocess.CalledProcessError:
        raise RuntimeError(f"ffmpeg –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª: {input_path}")


def seconds_to_timestamp(seconds: float) -> str:
    """
    –ü–µ—Ä–µ–≤–æ–¥ —Å–µ–∫—É–Ω–¥—ã -> —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ç–∞–π–º–∫–æ–¥ HH:MM:SS.mmm
    –£–¥–æ–±–Ω–æ –¥–ª—è —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã—Ö .txt.
    """
    if seconds < 0:
        seconds = 0.0
    milliseconds_total: int = int(round(seconds * 1000))
    hours: int = milliseconds_total // (3600 * 1000)
    minutes: int = (milliseconds_total % (3600 * 1000)) // (60 * 1000)
    seconds_int: int = (milliseconds_total % (60 * 1000)) // 1000
    milliseconds: int = milliseconds_total % 1000
    return f"{hours:02d}:{minutes:02d}:{seconds_int:02d}.{milliseconds:03d}"


# --------------------
# –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è + ASR
# --------------------

def run_diarization(wav_path: str, num_speakers: Optional[int]) -> List[Dict[str, Union[float, str]]]:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç simple_diarizer –Ω–∞–¥ WAV-—Ñ–∞–π–ª–æ–º.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∫–ª—é—á–∞–º–∏: start, end, label (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö –∏ —Ç–µ–∫—Å—Ç–æ–≤–∞—è –º–µ—Ç–∫–∞ —Å–ø–∏–∫–µ—Ä–∞).
    """
    # –ü—Ä–æ—Å—Ç–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: —ç–º–±–µ–¥–¥–µ—Ä –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏ spectral clustering.
    diarizer: Diarizer = Diarizer()  # –º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å embed_model='xvec'|'ecapa', cluster_method='sc'|'ahc'
    if num_speakers is not None and num_speakers > 0:
        raw_segments = diarizer.diarize(wav_path, num_speakers=num_speakers)
    else:
        raw_segments = diarizer.diarize(wav_path)

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –æ–¥–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
    normalized: List[Dict[str, Union[float, str]]] = []
    for segment in raw_segments:
        # segment –º–æ–∂–µ—Ç –±—ã—Ç—å tuple(start, end, label) –∏–ª–∏ dict —Å —Ç–∞–∫–∏–º–∏ –∫–ª—é—á–∞–º–∏ ‚Äî –ø—Ä–∏–≤–µ–¥—ë–º –∞–∫–∫—É—Ä–∞—Ç–Ω–æ
        if isinstance(segment, (list, tuple)) and len(segment) >= 3:
            start_val, end_val, label_val = segment[0], segment[1], segment[2]
            normalized.append({"start": float(start_val), "end": float(end_val), "label": str(label_val)})
        elif isinstance(segment, dict):
            start_val = float(segment.get("start", 0.0))
            end_val = float(segment.get("end", 0.0))
            label_val = str(segment.get("label", "SPEAKER"))
            normalized.append({"start": start_val, "end": end_val, "label": label_val})
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞—á–∞–ª–∞ –¥–ª—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º–∞
    normalized.sort(key=lambda x: float(x["start"]))
    return normalized


def remap_speaker_labels(diar_segments: List[Dict[str, Union[float, str]]]) -> Dict[str, str]:
    """
    –ü—Ä–∏–≤–æ–¥–∏—Ç –ª—é–±—ã–µ –∏—Å—Ö–æ–¥–Ω—ã–µ –ª–µ–π–±–ª—ã –∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º SPEAKER_1..N.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ {–∏—Å—Ö–æ–¥–Ω—ã–π_–ª–µ–π–±–ª -> –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π_–ª–µ–π–±–ª}.
    """
    mapping: Dict[str, str] = {}
    counter: int = 1
    for seg in diar_segments:
        original_label: str = str(seg["label"])
        if original_label not in mapping:
            mapping[original_label] = f"{SPEAKER_PREFIX}{counter}"
            counter += 1
    return mapping


def run_whisper_with_segments(wav_path: str, model_name: str, language: str) -> List[Dict[str, Union[float, str]]]:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç Whisper –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: start, end, text.
    """
    model = whisper.load_model(model_name)
    # Whisper —Å–∞–º –∏–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ WAV; –≤–∞–∂–Ω–æ, —á—Ç–æ —É –Ω–∞—Å —É–∂–µ 16–∫–ì—Ü –º–æ–Ω–æ
    result = model.transcribe(wav_path, language=language, verbose=False)
    segments: List[Dict[str, Union[float, str]]] = []
    for seg in result.get("segments", []):
        start_val: float = float(seg.get("start", 0.0))
        end_val: float = float(seg.get("end", 0.0))
        text_val: str = str(seg.get("text", "")).strip()
        if end_val > start_val and text_val:
            segments.append({"start": start_val, "end": end_val, "text": text_val})
    return segments


def compute_overlap(a_start: float, a_end: float, b_start: float, b_end: float) -> float:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –¥–≤—É—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ [a_start, a_end] –∏ [b_start, b_end]."""
    left: float = max(a_start, b_start)
    right: float = min(a_end, b_end)
    return max(0.0, right - left)


def assign_speaker_to_asr_segment(
    asr_start: float,
    asr_end: float,
    diar_segments: List[Dict[str, Union[float, str]]],
) -> Optional[str]:
    """
    –ù–∞–∑–Ω–∞—á–∞–µ—Ç —Å–ø–∏–∫–µ—Ä–∞ ASR-—Å–µ–≥–º–µ–Ω—Ç—É –ø–æ –ø—Ä–∞–≤–∏–ª—É:
    1) –ë–µ—Ä—ë–º —Å–µ—Ä–µ–¥–∏–Ω—É —Å–µ–≥–º–µ–Ω—Ç–∞ –∏ –∏—â–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏, –∫—É–¥–∞ –æ–Ω–∞ –ø–æ–ø–∞–¥–∞–µ—Ç.
    2) –ï—Å–ª–∏ —Ç–∞–∫–∏—Ö –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–ª–∏ —Å–µ—Ä–µ–¥–∏–Ω–∞ ¬´–Ω–∞ –≥—Ä–∞–Ω–∏—Ü–µ¬ª, –≤—ã–±–∏—Ä–∞–µ–º –ø–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–º—É –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—é.
    3) –ï—Å–ª–∏ –≤–æ–æ–±—â–µ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –Ω–µ—Ç (–∫—Ä–∞–π–Ω–∏–π —Å–ª—É—á–∞–π) ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None.
    """
    midpoint: float = (asr_start + asr_end) / 2.0

    # –ö–∞–Ω–¥–∏–¥–∞—Ç—ã –ø–æ –ø–æ–ø–∞–¥–∞–Ω–∏—é —Å–µ—Ä–µ–¥–∏–Ω—ã
    candidates: List[Tuple[str, float]] = []
    for seg in diar_segments:
        d_start: float = float(seg["start"])
        d_end: float = float(seg["end"])
        d_label: str = str(seg["label"])

        # –°–µ—Ä–µ–¥–∏–Ω–∞ –ø–æ–ø–∞–ª–∞ –≤ –∏–Ω—Ç–µ—Ä–≤–∞–ª?
        if d_start <= midpoint <= d_end:
            # –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –≤—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ –¥–ª—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –Ω–∞ –≥—Ä–∞–Ω–∏—Ü–∞—Ö
            overlap: float = compute_overlap(asr_start, asr_end, d_start, d_end)
            if overlap > 0:
                candidates.append((d_label, overlap))

    if candidates:
        # –í—ã–±–∏—Ä–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º
        candidates.sort(key=lambda pair: pair[1], reverse=True)
        return candidates[0][0]

    # –ï—Å–ª–∏ —Å–µ—Ä–µ–¥–∏–Ω–∞ –Ω–µ –ø–æ–ø–∞–ª–∞ –Ω–∏–∫—É–¥–∞ (—Ä–µ–¥–∫–∏–π —Å–ª—É—á–∞–π), –≤—ã–±–∏—Ä–∞–µ–º –ø–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–º—É –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—é –≤–æ–æ–±—â–µ
    best_label: Optional[str] = None
    best_overlap: float = 0.0
    for seg in diar_segments:
        d_start = float(seg["start"])
        d_end = float(seg["end"])
        d_label = str(seg["label"])
        overlap = compute_overlap(asr_start, asr_end, d_start, d_end)
        if overlap > best_overlap:
            best_overlap = overlap
            best_label = d_label

    return best_label


def save_outputs(
    base_name: str,
    assigned_segments: List[Dict[str, Union[float, str]]],
    output_folder: str,
) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç .diarized.txt –∏ .diarized.json –≤ output_folder.
    assigned_segments: —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ {start, end, speaker, text}
    """
    txt_path: str = os.path.join(output_folder, f"{base_name}.diarized.txt")
    json_path: str = os.path.join(output_folder, f"{base_name}.diarized.json")

    # –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π TXT
    with open(txt_path, "w", encoding="utf-8") as f_txt:
        for seg in assigned_segments:
            start_ts: str = seconds_to_timestamp(float(seg["start"]))
            end_ts: str = seconds_to_timestamp(float(seg["end"]))
            speaker: str = str(seg["speaker"])
            text: str = str(seg["text"])
            f_txt.write(f"[{start_ts}‚Äì{end_ts}] {speaker}: {text}\n")

    # –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON
    with open(json_path, "w", encoding="utf-8") as f_json:
        json.dump(assigned_segments, f_json, ensure_ascii=False, indent=2)

    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {os.path.basename(txt_path)} –∏ {os.path.basename(json_path)}")


def process_one_file(input_path: str, num_speakers: Optional[int]) -> None:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª:
    - –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ WAV 16k –º–æ–Ω–æ,
    - –∑–∞–ø—É—Å–∫–∞–µ—Ç –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é,
    - –∑–∞–ø—É—Å–∫–∞–µ—Ç Whisper,
    - —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.
    
    Args:
        input_path: –ø—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
        num_speakers: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤ (None –¥–ª—è –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)
    """
    file_stem: str = os.path.splitext(os.path.basename(input_path))[0]
    wav_path: str = os.path.join(TEMP_AUDIO_FOLDER, f"{file_stem}.16k_mono.wav")

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∫ —Ü–µ–ª–µ–≤–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
    if input_path.lower().endswith(".wav"):
        # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π —Ç–æ–∂–µ –ø—Ä–∏–≤–æ–¥–∏–º –∫ 16k/mono (—á—Ç–æ–±—ã –Ω–µ –ª–æ–≤–∏—Ç—å –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞)
        run_ffmpeg_to_wav_16k_mono(input_path, wav_path)
    else:
        run_ffmpeg_to_wav_16k_mono(input_path, wav_path)

    # –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è
    print(f"üß© –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è (–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏–∫–µ—Ä–æ–≤): {os.path.basename(input_path)} ...")
    diar_segments = run_diarization(wav_path, num_speakers)
    if not diar_segments:
        print("‚ö†Ô∏è –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ —Å–µ–≥–º–µ–Ω—Ç—ã. –ü—Ä–æ–¥–æ–ª–∂–∞—é –±–µ–∑ —Å–ø–∏–∫–µ—Ä–æ–≤ (–≤—Å–µ –∫–∞–∫ SPEAKER_1).")

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –º–µ—Ç–∫–∏ —Å–ø–∏–∫–µ—Ä–æ–≤ –≤ SPEAKER_1..N
    label_map = remap_speaker_labels(diar_segments)
    for seg in diar_segments:
        original = str(seg["label"])
        seg["label"] = label_map.get(original, original)

    # ASR (Whisper) ‚Äî —Å–µ–≥–º–µ–Ω—Ç—ã —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏ –∏ —Ç–µ–∫—Å—Ç–æ–º
    print(f"üîä –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ —Ä–µ—á–∏ Whisper: {os.path.basename(input_path)} ...")
    asr_segments = run_whisper_with_segments(wav_path, WHISPER_MODEL_NAME, WHISPER_LANGUAGE)

    # –ú–∞–ø–ø–∏–Ω–≥: –∫–∞–∂–¥–æ–º—É ASR-—Å–µ–≥–º–µ–Ω—Ç—É –Ω–∞–∑–Ω–∞—á–∞–µ–º —Å–ø–∏–∫–µ—Ä–∞
    assigned: List[Dict[str, Union[float, str]]] = []
    for seg in asr_segments:
        seg_start: float = float(seg["start"])
        seg_end: float = float(seg["end"])
        seg_text: str = str(seg["text"])
        if diar_segments:
            chosen_label: Optional[str] = assign_speaker_to_asr_segment(seg_start, seg_end, diar_segments)
            speaker_label: str = chosen_label if chosen_label is not None else f"{SPEAKER_PREFIX}1"
        else:
            speaker_label = f"{SPEAKER_PREFIX}1"

        assigned.append({
            "start": seg_start,
            "end": seg_end,
            "speaker": speaker_label,
            "text": seg_text,
        })

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –æ–¥–Ω—É –ø–∞–ø–∫—É
    save_outputs(file_stem, assigned, OUTPUT_FOLDER)


def parse_arguments() -> argparse.Namespace:
    """
    –ü–∞—Ä—Å–∏—Ç –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏.
    
    Returns:
        Namespace —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏ (speakers)
    """
    parser = argparse.ArgumentParser(
        description="–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Å–ø–∏–∫–µ—Ä–æ–≤ (speaker diarization)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python transcribe_diarize.py              # –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ø–∏–∫–µ—Ä–æ–≤
  python transcribe_diarize.py -s 2         # 2 —Å–ø–∏–∫–µ—Ä–∞
  python transcribe_diarize.py --speakers 3 # 3 —Å–ø–∏–∫–µ—Ä–∞
        """
    )
    
    parser.add_argument(
        "-s", "--speakers",
        type=int,
        default=None,
        metavar="N",
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)"
    )
    
    return parser.parse_args()


def main() -> None:
    # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    args = parse_arguments()
    num_speakers = args.speakers
    
    if num_speakers is not None:
        print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤: {num_speakers}")
    else:
        print("üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤: –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ")
    
    ensure_directories()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º Whisper –º–æ–¥–µ–ª—å –æ–¥–∏–Ω —Ä–∞–∑ (—É—Å–∫–æ—Ä—è–µ—Ç —Å–µ—Ä–∏—é —Ñ–∞–π–ª–æ–≤)
    # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º —Ñ–∞–π–ª—ã –≤–æ –≤—Ö–æ–¥–Ω–æ–π –ø–∞–ø–∫–µ
    input_files: List[str] = []
    for filename in os.listdir(AUDIO_FOLDER):
        if not is_supported(filename):
            continue
        input_files.append(os.path.join(AUDIO_FOLDER, filename))

    if not input_files:
        print("‚ö†Ô∏è –í –ø–∞–ø–∫–µ 'audio' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ–∞–π–ª–æ–≤.")
        return

    for input_path in input_files:
        print(f"üéûÔ∏è –ì–æ—Ç–æ–≤–ª—é: {os.path.basename(input_path)}")
        try:
            process_one_file(input_path, num_speakers)
        except Exception as error:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {os.path.basename(input_path)}: {error}")

    print("üéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")


if __name__ == "__main__":
    main()
