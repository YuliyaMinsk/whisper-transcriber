# –ù—É–∂–µ–Ω –ø–∏—Ç–æ–Ω 3.11.9, –º–æ–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ, –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏.
# –î–ª—è –∑–∞–ø—É—Å–∫–∞, –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞ –∑–∞–ø—É—Å–∫–∞–µ–º –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–ø—Ç:
#
# source .venv/bin/activate
# python transcribe.py

import os
import subprocess
import torch
from transformers import pipeline
from typing import List, Tuple

# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ---
# –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –±—ã—Å—Ç—Ä–µ–µ, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 'small' –∏–ª–∏ 'base' –º–æ–¥–µ–ª–∏
WHISPER_MODEL_NAME: str = "medium" 
WHISPER_LANGUAGE: str = "ru"

AUDIO_FOLDER: str = "audio"
OUTPUT_FOLDER: str = "transcripts"
TEMP_AUDIO_FOLDER: str = "temp_audio"

SUPPORTED_EXTENSIONS: Tuple[str, ...] = (".ogg", ".opus", ".mp3", ".wav", ".m4a", ".mp4")

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ASR Pipeline ---

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (MPS –¥–ª—è Apple Silicon)
if torch.backends.mps.is_available():
    DEVICE: str = "mps"
    print("üí° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å–∫–æ—Ä–µ–Ω–∏–µ MPS (GPU) –¥–ª—è ASR.")
elif torch.cuda.is_available():
    DEVICE: str = "cuda"
    print("üí° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å–∫–æ—Ä–µ–Ω–∏–µ CUDA (GPU) –¥–ª—è ASR.")
else:
    DEVICE: str = "cpu"
    print("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU –¥–ª—è ASR.")

# –°–æ–∑–¥–∞–µ–º ASR Pipeline, –∫–æ—Ç–æ—Ä—ã–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä,
# –∞ —Ç–∞–∫–∂–µ —É–ø—Ä–∞–≤–ª—è–µ—Ç –æ—Ç–ø—Ä–∞–≤–∫–æ–π –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ.
try:
    asr_pipeline = pipeline(
        "automatic-speech-recognition", 
        model=f"openai/whisper-{WHISPER_MODEL_NAME}",
        device=DEVICE,
        tokenizer=f"openai/whisper-{WHISPER_MODEL_NAME}",
        chunk_length_s=30,  # –î–ª—è –ª—É—á—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª–∏–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    )
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ASR Pipeline: {e}")
    print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É torch, transformers –∏ accelerate.")
    exit(1)


def run_ffmpeg_audio_extract(input_path: str, output_path: str) -> None:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, MP4) –≤ MP3."""
    command: List[str] = [
        "ffmpeg", "-y", "-i", input_path,
        "-vn", "-acodec", "libmp3lame",
        output_path
    ]
    try:
        subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
    except subprocess.CalledProcessError:
        print(f"‚ùå FFmpeg –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª: {input_path}")
        raise

def main() -> None:
    os.makedirs(TEMP_AUDIO_FOLDER, exist_ok=True)
    os.makedirs(OUTPUT_FOLDER, exist_ok=True)

    input_files: List[str] = [
        os.path.join(AUDIO_FOLDER, f) 
        for f in os.listdir(AUDIO_FOLDER) 
        if f.lower().endswith(SUPPORTED_EXTENSIONS)
    ]

    if not input_files:
        print(f"‚ö†Ô∏è –í –ø–∞–ø–∫–µ '{AUDIO_FOLDER}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ–∞–π–ª–æ–≤.")
        return

    for input_path in input_files:
        filename = os.path.basename(input_path)
        file_stem = os.path.splitext(filename)[0]

        audio_only_path: str
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–æ–≤
        if filename.lower().endswith(".mp4"):
            audio_only_path = os.path.join(TEMP_AUDIO_FOLDER, file_stem + ".mp3")
            print(f"üéûÔ∏è –ò–∑–≤–ª–µ–∫–∞—é –∑–≤—É–∫ –∏–∑ {filename}...")
            try:
                run_ffmpeg_audio_extract(input_path, audio_only_path)
            except Exception:
                continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª –ø—Ä–∏ –æ—à–∏–±–∫–µ FFmpeg
        else:
            audio_only_path = input_path

        # –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ —Å –ø–æ–º–æ—â—å—é Hugging Face Pipeline
        print(f"üîä –†–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞—é: {filename}...")
        try:
            # Pipeline –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ dict'–æ–≤, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç
            result = asr_pipeline(
                audio_only_path, 
                generate_kwargs={"language": WHISPER_LANGUAGE}
            )
            transcribed_text: str = result[0]["text"]
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ {filename}: {e}")
            continue

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        text_filename = file_stem + ".txt"
        output_path = os.path.join(OUTPUT_FOLDER, text_filename)
        
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(transcribed_text)

        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {text_filename}\n")

    print("üéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")


if __name__ == "__main__":
    main()