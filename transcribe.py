# –ù—É–∂–µ–Ω –ø–∏—Ç–æ–Ω 3.11.9, –º–æ–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ, –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏.
# –î–ª—è –∑–∞–ø—É—Å–∫–∞, –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞ –∑–∞–ø—É—Å–∫–∞–µ–º –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–ø—Ç:
#
# source .venv/bin/activate
# python transcribe.py

import os
import whisper
import subprocess

model = whisper.load_model("base")

audio_folder = "audio"
output_folder = "transcripts"
temp_audio_folder = "temp_audio"

os.makedirs(temp_audio_folder, exist_ok=True)
os.makedirs(output_folder, exist_ok=True)

SUPPORTED_EXTENSIONS = (".ogg", ".opus", ".mp3", ".wav", ".m4a", ".mp4")

for filename in os.listdir(audio_folder):
    if not filename.lower().endswith(SUPPORTED_EXTENSIONS):
        continue

    input_path = os.path.join(audio_folder, filename)

    # –ï—Å–ª–∏ —ç—Ç–æ mp4 ‚Äî –∏–∑–≤–ª–µ–∫–∞–µ–º –∑–≤—É–∫ –≤ mp3, –∏–Ω–∞—á–µ –ø–æ–¥–∞—ë–º —Ñ–∞–π–ª –Ω–∞–ø—Ä—è–º—É—é
    if filename.lower().endswith(".mp4"):
        audio_only_path = os.path.join(
            temp_audio_folder, os.path.splitext(filename)[0] + ".mp3"
        )
        print(f"üéûÔ∏è –ò–∑–≤–ª–µ–∫–∞—é –∑–≤—É–∫ –∏–∑ {filename}...")
        subprocess.run(
            [
                "ffmpeg", "-y", "-i", input_path,
                "-vn", "-acodec", "libmp3lame",
                audio_only_path
            ],
            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=False
        )
    else:
        audio_only_path = input_path

    print(f"üîä –†–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞—é: {filename}...")
    result = model.transcribe(audio_only_path, language="ru")
    text_filename = os.path.splitext(filename)[0] + ".txt"

    with open(os.path.join(output_folder, text_filename), "w", encoding="utf-8") as f:
        f.write(result["text"])

    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {text_filename}\n")

print("üéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
