# –ù—É–∂–µ–Ω –ø–∏—Ç–æ–Ω 3.11.9, –º–æ–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ, –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏.
# –î–ª—è –∑–∞–ø—É—Å–∫–∞, –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞ –∑–∞–ø—É—Å–∫–∞–µ–º –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–ø—Ç:
#
# source .venv/bin/activate
# python transcribe.py

import os
import subprocess
import torch
import time
from datetime import datetime
from transformers import pipeline
from typing import List, Tuple

# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ---
# –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –±—ã—Å—Ç—Ä–µ–µ, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 'small' –∏–ª–∏ 'base' –º–æ–¥–µ–ª–∏
WHISPER_MODEL_NAME: str = "medium" 
WHISPER_LANGUAGE: str = "ru"

AUDIO_FOLDER: str = "audio"
OUTPUT_FOLDER: str = "transcripts"
TEMP_AUDIO_FOLDER: str = "temp_audio"
LOG_FILE: str = "processing.log.csv"

SUPPORTED_EXTENSIONS: Tuple[str, ...] = (".ogg", ".opus", ".mp3", ".wav", ".m4a", ".mp4")

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---

def format_duration(seconds: float) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–µ–∫—É–Ω–¥—ã –≤ MM:SS –∏–ª–∏ HH:MM:SS (–∫–∞–∫ –≤ –¥—Ä—É–≥–æ–º —Å–∫—Ä–∏–ø—Ç–µ)."""
    seconds_int: int = int(seconds)
    hours: int = seconds_int // 3600
    minutes: int = (seconds_int % 3600) // 60
    secs: int = seconds_int % 60

    if hours > 0:
        return f"{hours}:{minutes:02d}:{secs:02d}"
    return f"{minutes}:{secs:02d}"


def write_log(
    filename: str,
    duration_seconds: float,
    num_speakers: int,
    processing_time_seconds: float,
) -> None:
    """
    –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤ –ª–æ–≥-—Ñ–∞–π–ª.
    """
    # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äî —Å–æ–∑–¥–∞—ë–º —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
    if not os.path.exists(LOG_FILE):
        with open(LOG_FILE, "w", encoding="utf-8") as log_file:
            log_file.write("timestamp,filename,speakers,duration_sec,model,processing_time_sec\n")

    timestamp: str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    duration_formatted: str = format_duration(duration_seconds)
    processing_time_formatted: str = format_duration(processing_time_seconds)

    with open(LOG_FILE, "a", encoding="utf-8") as log_file:
        log_file.write(
            f"{timestamp},{filename},{num_speakers},{duration_formatted},"
            f"{WHISPER_MODEL_NAME},{processing_time_formatted}\n"
        )


def get_audio_duration_seconds(file_path: str) -> float:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö —á–µ—Ä–µ–∑ ffprobe.
    –¢—Ä–µ–±—É–µ—Ç ffmpeg/ffprobe. –ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ ‚Äî –≤–µ—Ä–Ω—ë—Ç 0.0.
    """
    command: List[str] = [
        "ffprobe",
        "-v", "error",
        "-show_entries", "format=duration",
        "-of", "default=noprint_wrappers=1:nokey=1",
        file_path,
    ]
    try:
        result = subprocess.run(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.DEVNULL,
            text=True,
            check=True,
        )
        output: str = result.stdout.strip()
        if not output:
            return 0.0
        return float(output)
    except Exception:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è —Ñ–∞–π–ª–∞: {file_path}")
        return 0.0


# --- –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ ffmpeg ---

def convert_to_wav_16k_mono(input_path: str, output_path: str) -> None:
    """
    –ü—Ä–∏–≤–æ–¥–∏—Ç –ª—é–±–æ–π –≤—Ö–æ–¥ (–∞—É–¥–∏–æ/–≤–∏–¥–µ–æ) –∫ WAV 16 kHz mono.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≤—Å–µ—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤: .m4a, .mp3, .ogg, .mp4 –∏ —Ç.–¥.
    """
    command: List[str] = [
        "ffmpeg",
        "-y",
        "-i", input_path,
        "-vn",          # —É–±–∏—Ä–∞–µ–º –≤–∏–¥–µ–æ, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å
        "-ac", "1",     # 1 –∫–∞–Ω–∞–ª (mono)
        "-ar", "16000", # 16 kHz
        "-f", "wav",
        output_path,
    ]
    try:
        subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
    except subprocess.CalledProcessError as error:
        print(f"‚ùå FFmpeg –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª: {input_path}, –æ—à–∏–±–∫–∞: {error}")
        raise


# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ASR Pipeline ---

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (MPS –¥–ª—è Apple Silicon)
if torch.backends.mps.is_available():
    DEVICE: str = "mps"
    print("üí° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å–∫–æ—Ä–µ–Ω–∏–µ MPS (GPU) –¥–ª—è ASR.")
elif torch.cuda.is_available():
    DEVICE: str = "cuda"
    print("üí° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å–∫–æ—Ä–µ–Ω–∏–µ CUDA (GPU) –¥–ª—è ASR.")
else:
    DEVICE: str = "cpu"
    print("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU –¥–ª—è ASR.")

# –°–æ–∑–¥–∞–µ–º ASR Pipeline, –∫–æ—Ç–æ—Ä—ã–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä,
# –∞ —Ç–∞–∫–∂–µ —É–ø—Ä–∞–≤–ª—è–µ—Ç –æ—Ç–ø—Ä–∞–≤–∫–æ–π –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ.
try:
    asr_pipeline = pipeline(
        "automatic-speech-recognition", 
        model=f"openai/whisper-{WHISPER_MODEL_NAME}",
        device=DEVICE,
        tokenizer=f"openai/whisper-{WHISPER_MODEL_NAME}",
        chunk_length_s=30,  # –î–ª—è –ª—É—á—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª–∏–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    )
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ASR Pipeline: {e}")
    print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É torch, transformers –∏ accelerate.")
    exit(1)


def run_ffmpeg_audio_extract(input_path: str, output_path: str) -> None:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, MP4) –≤ MP3."""
    command: List[str] = [
        "ffmpeg", "-y", "-i", input_path,
        "-vn", "-acodec", "libmp3lame",
        output_path
    ]
    try:
        subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
    except subprocess.CalledProcessError:
        print(f"‚ùå FFmpeg –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª: {input_path}")
        raise


def main() -> None:
    os.makedirs(TEMP_AUDIO_FOLDER, exist_ok=True)
    os.makedirs(OUTPUT_FOLDER, exist_ok=True)

    input_files: List[str] = [
        os.path.join(AUDIO_FOLDER, filename)
        for filename in os.listdir(AUDIO_FOLDER)
        if filename.lower().endswith(SUPPORTED_EXTENSIONS)
    ]

    if not input_files:
        print(f"‚ö†Ô∏è –í –ø–∞–ø–∫–µ '{AUDIO_FOLDER}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ–∞–π–ª–æ–≤.")
        return

    for input_path in input_files:
        filename: str = os.path.basename(input_path)
        file_stem: str = os.path.splitext(filename)[0]

        print(f"üéûÔ∏è –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞—é –∞—É–¥–∏–æ: {filename}...")
        processing_start_time: float = time.time()

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –ª—é–±–æ–π —Ñ–∞–π–ª –≤ temp WAV 16k mono
        prepared_wav_path: str = os.path.join(TEMP_AUDIO_FOLDER, f"{file_stem}.16k.wav")
        try:
            convert_to_wav_16k_mono(input_path, prepared_wav_path)
        except Exception:
            # –ï—Å–ª–∏ ffmpeg –Ω–µ —Å–ø—Ä–∞–≤–∏–ª—Å—è ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª
            continue

        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ø–æ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω–æ–º—É WAV
        print(f"üîä –†–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞—é: {filename}...")
        try:
            result = asr_pipeline(
                prepared_wav_path,
                generate_kwargs={"language": WHISPER_LANGUAGE},
            )

            # –£ —Ä–∞–∑–Ω—ã—Ö –≤–µ—Ä—Å–∏–π transformers —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å dict –∏–ª–∏ list[dict]
            if isinstance(result, list):
                transcribed_text: str = str(result[0]["text"])
            else:
                transcribed_text = str(result["text"])
        except Exception as error:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ {filename}: {error}")
            continue

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç
        text_filename: str = file_stem + ".txt"
        output_path: str = os.path.join(OUTPUT_FOLDER, text_filename)
        with open(output_path, "w", encoding="utf-8") as output_file:
            output_file.write(transcribed_text)

        # –õ–æ–≥–∏—Ä—É–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        duration_seconds: float = get_audio_duration_seconds(input_path)  # –ø–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—É
        processing_time_seconds: float = time.time() - processing_start_time

        write_log(
            filename=filename,
            duration_seconds=duration_seconds,
            num_speakers=1,
            processing_time_seconds=processing_time_seconds,
        )

        print(
            f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {text_filename}\n"
            f"‚è± –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ–∞–π–ª–∞: {format_duration(duration_seconds)}, "
            f"–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–Ω—è–ª–∞: {format_duration(processing_time_seconds)}\n"
        )

    print("üéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")


if __name__ == "__main__":
    main()
